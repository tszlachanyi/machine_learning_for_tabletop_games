{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reinforcement learning\n",
    "#Input = board (One-hot)\n",
    "#Output = move\n",
    "\"\"\"\n",
    "player functions to use in play_game method:\n",
    "random_player - randomly chooses from available moves\n",
    "human_player - takes keyboard input to choose from the list of available moves. input example : \"1, 0, 2, 0\" moves the\n",
    "               chess piece from 1,0 coordinates to 2,0 coordinates\n",
    "min_max_player - runs the min-max algorithm to choose the best available move\n",
    "make_move - player trained with reinforced learning\n",
    "\"\"\"\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def _new_board():\n",
    "    \"\"\"Return a emprty chess board we can use for simulating a game.\n",
    "    Returns:\n",
    "        8x8 tuple of ints\n",
    "    \"\"\"\n",
    "    return (('R', 'N', 'B', 'Q', 'K', 'B', 'N', 'R'),\n",
    "            ('P', 'P', 'P', 'P', 'P', 'P', 'P', 'P'),\n",
    "            (0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           (0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           (0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           (0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           ('p', 'p', 'p', 'p', 'p', 'p', 'p', 'p'),\n",
    "           ('r', 'n', 'b', 'q', 'k', 'b', 'n', 'r'))\n",
    "\n",
    "\n",
    "def apply_move(board_state, move):\n",
    "    \"\"\"Returns a copy of the given board_state with the desired move applied.\n",
    "    Args:\n",
    "        board_state (3x3 tuple of int): The given board_state we want to apply the move to.\n",
    "        move (int, int): The position we want to make the move in.\n",
    "        side (int): The side we are making this move for, 1 for the first player, -1 for the second player.\n",
    "    Returns:\n",
    "        (3x3 tuple of int): A copy of the board_state with the given move applied for the given side.\n",
    "    \"\"\"\n",
    "    from_x, from_y, to_x, to_y = move\n",
    "\n",
    "    def get_tuples():\n",
    "        temp = list(board_state)\n",
    "        \n",
    "        for x in range(8):\n",
    "            for y in range(8):\n",
    "                if(from_x == x and from_y == y):\n",
    "                    chess_piece=temp[x][y]\n",
    "                    temp[x]=list(temp[x])\n",
    "                    temp[x][y]=0\n",
    "                    temp[x]=tuple(temp[x])\n",
    "                    \n",
    "        for x in range(8):\n",
    "            for y in range(8):\n",
    "                if(to_x == x and to_y == y):\n",
    "                    temp[x]=list(temp[x])\n",
    "                    temp[x][y]=chess_piece\n",
    "                    temp[x]=tuple(temp[x])\n",
    "        \n",
    "        \n",
    "        return tuple(temp)\n",
    "        \n",
    "    return tuple(get_tuples())\n",
    "\n",
    "\n",
    "def is_white(board_state, x, y):\n",
    "    #returns if the piece on x,y coordinates is white or not\n",
    "    if (board_state[x][y]=='p' or board_state[x][y]=='r' or board_state[x][y]=='n' or board_state[x][y]=='b' or board_state[x][y]=='q' or board_state[x][y]=='k') :\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def is_black(board_state, x, y):\n",
    "    #returns if the piece on x,y coordinates is black or not\n",
    "    if (board_state[x][y]=='P' or board_state[x][y]=='R' or board_state[x][y]=='N' or board_state[x][y]=='B' or board_state[x][y]=='Q' or board_state[x][y]=='K') :\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def available_moves(board_state, side):\n",
    "    \"\"\"Get all legal moves for the current board_state.\n",
    "    Args:\n",
    "        board_state: The board_state we want to check for valid moves.\n",
    "    Returns:\n",
    "        Generator of (int, int): All the valid moves that can be played in this position.\n",
    "    \"\"\"\n",
    "    for x, y in itertools.product(range(8), range(8)):\n",
    "        \n",
    "        if (side == 1):\n",
    "        #white player:\n",
    "        \n",
    "            if (board_state[x][y] == 'p'):\n",
    "            #white pawn:\n",
    "            \n",
    "                if (x>0 and board_state[x-1][y] == 0): #forward 1\n",
    "                    yield (x, y, x-1, y)\n",
    "                if (x==6 and board_state[x-1][y] == 0 and board_state[x-2][y] == 0): #forward 2\n",
    "                    yield (x, y, x-2, y)\n",
    "                if (x>0 and y>0 and is_black(board_state, x-1, y-1)): # forward 1 left 1\n",
    "                    yield (x, y, x-1, y-1)\n",
    "                if (x>0 and y<7 and is_black(board_state, x-1, y+1)): # forward 1 right 1\n",
    "                    yield (x, y, x-1, y+1)\n",
    "\n",
    "                    \n",
    "            if (board_state[x][y] == 'k'):\n",
    "            #white king:\n",
    "            \n",
    "                directions=[[1,1],[-1,-1],[1,-1],[-1,1],[1,0],[-1,0],[0,-1],[0,1]] #directions the chess piece can move in\n",
    "                for i in directions:\n",
    "                    if(x+i[0]<8 and x+i[0]>-1 and y+i[1]<8 and y+i[1]>-1):\n",
    "                        if(is_white(board_state,x+i[0],y+i[1])==False):\n",
    "                            yield(x, y, x+i[0], y+i[1])\n",
    "                    \n",
    "                    \n",
    "            if (board_state[x][y] == 'r'):\n",
    "            #white rook:\n",
    "            \n",
    "                directions=[[1,0],[-1,0],[0,-1],[0,1]]\n",
    "                for i in directions:\n",
    "                        blocked=0\n",
    "                        coordinates=[x,y]\n",
    "                        while(blocked==0 and coordinates[0]+i[0]<8 and coordinates[0]+i[0]>-1 and coordinates[1]+i[1]<8 and coordinates[1]+i[1]>-1):\n",
    "                            coordinates[0]+=i[0]\n",
    "                            coordinates[1]+=i[1]\n",
    "                            if(is_white(board_state,coordinates[0],coordinates[1])):\n",
    "                                blocked=1\n",
    "                            else:\n",
    "                                if(is_black(board_state,coordinates[0],coordinates[1])):\n",
    "                                    blocked=1\n",
    "                                yield (x, y, coordinates[0], coordinates[1])\n",
    " \n",
    "            if (board_state[x][y] == 'b'):\n",
    "            #white bishop:\n",
    "            \n",
    "                directions=[[1,1],[-1,-1],[1,-1],[-1,1]]\n",
    "                for i in directions:\n",
    "                        blocked=0\n",
    "                        coordinates=[x,y]\n",
    "                        while(blocked==0 and coordinates[0]+i[0]<8 and coordinates[0]+i[0]>-1 and coordinates[1]+i[1]<8 and coordinates[1]+i[1]>-1):\n",
    "                            coordinates[0]+=i[0]\n",
    "                            coordinates[1]+=i[1]\n",
    "                            if(is_white(board_state,coordinates[0],coordinates[1])):\n",
    "                                blocked=1\n",
    "                            else:\n",
    "                                if(is_black(board_state,coordinates[0],coordinates[1])):\n",
    "                                    blocked=1\n",
    "                                yield (x, y, coordinates[0], coordinates[1])\n",
    "                                \n",
    "                                \n",
    "                                \n",
    "            if (board_state[x][y] == 'q'):\n",
    "            #white queen:\n",
    "            \n",
    "                directions=[[1,1],[-1,-1],[1,-1],[-1,1],[1,0],[-1,0],[0,-1],[0,1]]\n",
    "                for i in directions:\n",
    "                        blocked=0\n",
    "                        coordinates=[x,y]\n",
    "                        while(blocked==0 and coordinates[0]+i[0]<8 and coordinates[0]+i[0]>-1 and coordinates[1]+i[1]<8 and coordinates[1]+i[1]>-1):\n",
    "                            coordinates[0]+=i[0]\n",
    "                            coordinates[1]+=i[1]\n",
    "                            if(is_white(board_state,coordinates[0],coordinates[1])):\n",
    "                                blocked=1\n",
    "                            else:\n",
    "                                if(is_black(board_state,coordinates[0],coordinates[1])):\n",
    "                                    blocked=1\n",
    "                                yield (x, y, coordinates[0], coordinates[1])\n",
    "                                \n",
    "            if (board_state[x][y] == 'n'):\n",
    "            #white knight:\n",
    "            \n",
    "                directions=[[1,2],[1,-2],[-1,2],[-1,-2],[2,1],[2,-1],[-2,1],[-2,-1]]\n",
    "                for i in directions:\n",
    "                    if(x+i[0]<8 and x+i[0]>-1 and y+i[1]<8 and y+i[1]>-1):\n",
    "                        if(is_white(board_state,x+i[0],y+i[1])==False):\n",
    "                            yield(x, y, x+i[0], y+i[1])\n",
    "\n",
    "\n",
    "        if (side == -1):\n",
    "        #black player:\n",
    "            \n",
    "            if (board_state[x][y] == 'P' and side == -1):\n",
    "                #black pawn:\n",
    "            \n",
    "                if (x<7 and board_state[x+1][y] == 0): #forward 1\n",
    "                    yield (x, y, x+1, y)\n",
    "                if (x==1 and board_state[x+1][y] == 0 and is_black(board_state, x+2, y)==False): #forward 2\n",
    "                    yield (x, y, x+2, y)\n",
    "                if (x<7 and y>0 and is_white(board_state, x+1, y-1)): # forward 1 left 1\n",
    "                    yield (x, y, x+1, y-1)\n",
    "                if (x<7 and y<7 and is_white(board_state, x+1, y+1)): # forward 1 right 1\n",
    "                    yield (x, y, x+1, y+1)\n",
    "\n",
    "                    \n",
    "                    \n",
    "            if (board_state[x][y] == 'K'):\n",
    "            #white king:\n",
    "            \n",
    "                directions=[[1,1],[-1,-1],[1,-1],[-1,1],[1,0],[-1,0],[0,-1],[0,1]]\n",
    "                for i in directions:\n",
    "                    if(x+i[0]<8 and x+i[0]>-1 and y+i[1]<8 and y+i[1]>-1):\n",
    "                        if(is_black(board_state,x+i[0],y+i[1])==False):\n",
    "                            yield(x, y, x+i[0], y+i[1])\n",
    "                            \n",
    "                            \n",
    "                    \n",
    "\n",
    "            if (board_state[x][y] == 'R'):\n",
    "            #black rook:\n",
    "            \n",
    "                directions=[[1,0],[-1,0],[0,-1],[0,1]]\n",
    "                for i in directions:\n",
    "                        blocked=0\n",
    "                        coordinates=[x,y]\n",
    "                        while(blocked==0 and coordinates[0]+i[0]<8 and coordinates[0]+i[0]>-1 and coordinates[1]+i[1]<8 and coordinates[1]+i[1]>-1):\n",
    "                            coordinates[0]+=i[0]\n",
    "                            coordinates[1]+=i[1]\n",
    "                            if(is_black(board_state,coordinates[0],coordinates[1])):\n",
    "                                blocked=1\n",
    "                            else:\n",
    "                                if(is_white(board_state,coordinates[0],coordinates[1])):\n",
    "                                    blocked=1\n",
    "                                yield (x, y, coordinates[0], coordinates[1])\n",
    "                                \n",
    "            if (board_state[x][y] == 'B'):\n",
    "            #black bishop:\n",
    "            \n",
    "                directions=[[1,1],[-1,-1],[1,-1],[-1,1]]\n",
    "                for i in directions:\n",
    "                        blocked=0\n",
    "                        coordinates=[x,y]\n",
    "                        while(blocked==0 and coordinates[0]+i[0]<8 and coordinates[0]+i[0]>-1 and coordinates[1]+i[1]<8 and coordinates[1]+i[1]>-1):\n",
    "                            coordinates[0]+=i[0]\n",
    "                            coordinates[1]+=i[1]\n",
    "                            if(is_black(board_state,coordinates[0],coordinates[1])):\n",
    "                                blocked=1\n",
    "                            else:\n",
    "                                if(is_white(board_state,coordinates[0],coordinates[1])):\n",
    "                                    blocked=1\n",
    "                                yield (x, y, coordinates[0], coordinates[1])\n",
    "                                \n",
    "                                \n",
    "            if (board_state[x][y] == 'Q'):\n",
    "            #black queen:\n",
    "            \n",
    "                directions=[[1,1],[-1,-1],[1,-1],[-1,1],[1,0],[-1,0],[0,-1],[0,1]]\n",
    "                for i in directions:\n",
    "                        blocked=0\n",
    "                        coordinates=[x,y]\n",
    "                        while(blocked==0 and coordinates[0]+i[0]<8 and coordinates[0]+i[0]>-1 and coordinates[1]+i[1]<8 and coordinates[1]+i[1]>-1):\n",
    "                            coordinates[0]+=i[0]\n",
    "                            coordinates[1]+=i[1]\n",
    "                            if(is_black(board_state,coordinates[0],coordinates[1])):\n",
    "                                blocked=1\n",
    "                            else:\n",
    "                                if(is_white(board_state,coordinates[0],coordinates[1])):\n",
    "                                    blocked=1\n",
    "                                yield (x, y, coordinates[0], coordinates[1])\n",
    "                                \n",
    "                                \n",
    "            if (board_state[x][y] == 'N'):\n",
    "            #black knight:\n",
    "            \n",
    "                directions=[[1,2],[1,-2],[-1,2],[-1,-2],[2,1],[2,-1],[-2,1],[-2,-1]]\n",
    "                for i in directions:\n",
    "                    if(x+i[0]<8 and x+i[0]>-1 and y+i[1]<8 and y+i[1]>-1):\n",
    "                        if(is_black(board_state,x+i[0],y+i[1])==False):\n",
    "                            yield(x, y, x+i[0], y+i[1])\n",
    "\n",
    "                            \n",
    "\n",
    "def has_winner(board_state):\n",
    "    \"\"\"Determine if a player has won on the given board_state.\n",
    "    Args:\n",
    "        board_state (8x8 tuple of int): The current board_state we want to evaluate.\n",
    "    Returns:\n",
    "        int: 1 if player one has won, -1 if player 2 has won, otherwise 0.\n",
    "    \"\"\"\n",
    "    black_king=0\n",
    "    white_king=0\n",
    "    \n",
    "    for x in range(8):\n",
    "        for y in range(8):\n",
    "            if(board_state[x][y] == 'k'):\n",
    "                white_king=1\n",
    "            if(board_state[x][y] == 'K'):\n",
    "                black_king=1       \n",
    "    \n",
    "    if black_king==0:\n",
    "        return 1\n",
    "    if white_king==0:\n",
    "        return -1\n",
    "    \n",
    "    return 0  # no one has won, return 0 for a draw\n",
    "\n",
    "def print_board(board_state,move):\n",
    "  for i in range (len(board_state)):\n",
    "    for j in range (len(board_state[0])):\n",
    "      if((move[0]==i and move[1]==j) or (move[2]==i and move[3]==j)):\n",
    "        print(\"\\033[1;33m%s\" %board_state[i][j], end = '  ')\n",
    "      else:\n",
    "        print(\"\\033[1;30m%s\" %board_state[i][j], end = '  ')\n",
    "    print(\"\\n\")\n",
    "\n",
    "#converting board state to fen\n",
    "from more_itertools import run_length\n",
    "\n",
    "\n",
    "def convert_cell(value):\n",
    "    if value == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "\n",
    "def convert_rank(rank):\n",
    "    return ''.join(\n",
    "        value * count if value else str(count)\n",
    "        for value, count in run_length.encode(map(convert_cell, rank))\n",
    "    )\n",
    "\n",
    "\n",
    "def fen_from_board(board):\n",
    "    return '/'.join(map(convert_rank, board)) + ' w KQkq - 0 1'\n",
    "\n",
    "    \n",
    "def play_game(plus_player_func, minus_player_func, log=0, max_game_length=100):\n",
    "    \"\"\"Run a single game of tic-tac-toe until the end, using the provided function args to determine the moves for each\n",
    "    player.\n",
    "    Args:\n",
    "        plus_player_func ((board_state(3 by 3 tuple of int), side(int)) -> move((int, int))): Function that takes the\n",
    "            current board_state and side this player is playing, and returns the move the player wants to play.\n",
    "        minus_player_func ((board_state(3 by 3 tuple of int), side(int)) -> move((int, int))): Function that takes the\n",
    "            current board_state and side this player is playing, and returns the move the player wants to play.\n",
    "        log (bool): If True progress is logged to console, defaults to False\n",
    "    Returns:\n",
    "        int: 1 if the plus_player_func won, -1 if the minus_player_func won and 0 for a draw\n",
    "    \"\"\"\n",
    "    board_state = _new_board()\n",
    "    player_turn = 1\n",
    "    turn = 0\n",
    "    points=[]\n",
    "    while True:\n",
    "        _available_moves = list(available_moves(board_state, player_turn))\n",
    "        \n",
    "        turn=turn+1\n",
    "        \n",
    "        if len(_available_moves) == 0:\n",
    "            # draw\n",
    "            if log:\n",
    "                print(\"no moves left, game ended a draw\")\n",
    "            \n",
    "            return 0, points, turn\n",
    "        if player_turn > 0:\n",
    "            move = plus_player_func(board_state, 1)\n",
    "        else:\n",
    "            move = minus_player_func(board_state, -1)\n",
    "\n",
    "        if move not in _available_moves:\n",
    "            # if a player makes an invalid move the other player wins\n",
    "            if log:\n",
    "                print(\"illegal move \", move)\n",
    "            \n",
    "            if player_turn > 0:\n",
    "                points.append(player_turn*(-100))\n",
    "            return -player_turn, points, turn\n",
    "        \n",
    "        pre_move_point = position_points(board_state)\n",
    "        \n",
    "        board_state = apply_move(board_state, move)\n",
    "        \n",
    "        post_move_point = position_points(board_state)\n",
    "        \n",
    "        if player_turn > 0:\n",
    "            points.append(post_move_point-pre_move_point)\n",
    "        \n",
    "        if log==1:\n",
    "            \n",
    "            print(fen_from_board(board_state))\n",
    "            print_board(board_state,move)\n",
    "            print(\"___________\")\n",
    "            \n",
    "\n",
    "        if log==2:\n",
    "            \n",
    "            print(np.matrix(board_state))\n",
    "            print(\"___________\")\n",
    "\n",
    "        winner = has_winner(board_state)\n",
    "        if winner != 0:\n",
    "            if log:\n",
    "                print(\"we have a winner, side: %s\" % player_turn)\n",
    "            return winner, points, turn\n",
    "        player_turn = -player_turn\n",
    "        if turn == max_game_length:\n",
    "            return 0, points, turn\n",
    "\n",
    "def random_player(board_state, side):\n",
    "    \"\"\"A player func that can be used in the play_game method. Given a board state it chooses a move randomly from the\n",
    "    valid moves in the current state.\n",
    "    Args:\n",
    "        board_state (3x3 tuple of int): The current state of the board\n",
    "        _: the side this player is playing, not used in this function because we are simply choosing the moves randomly\n",
    "    Returns:\n",
    "        (int, int): the move we want to play on the current board\n",
    "    \"\"\"\n",
    "    moves = list(available_moves(board_state, side))\n",
    "    return random.choice(moves)\n",
    "\n",
    "\n",
    "def human_player(board_state,side):\n",
    "    moves = list(available_moves(board_state,side))\n",
    "    print(moves)\n",
    "    move = 0\n",
    "    while(move not in list(available_moves(board_state,side))):\n",
    "        move=input()\n",
    "        move = tuple(map(int, move.split(', '))) \n",
    "    return(move)\n",
    "\n",
    "def position_points(board_state):\n",
    "    pieces=['p','r','n','b','q','k','P','R','N','B','Q','K']\n",
    "    points=[1,5,3,3,9,100,-1,-5,-3,-3,-9,-100]\n",
    "    point=0\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            for k in range(12):\n",
    "                if(board_state[i][j]==pieces[k]):\n",
    "                    point=point+points[k]\n",
    "    return point\n",
    "                    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # example of playing a game\n",
    "    play_game(policy_gradient_player, random_player, log=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#policy_gradient\n",
    "\n",
    "\n",
    "import time\n",
    "import collections\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "print(tf.__version__)\n",
    "\n",
    "HIDDEN_NODES = (500, 500, 500)  # number of hidden layer neurons\n",
    "INPUT_NODES = 8 * 8 * 12  # board size * one hot vector length\n",
    "BATCH_SIZE = 100  # every how many games to do a parameter update?\n",
    "LEARN_RATE = 1e-4\n",
    "OUTPUT_NODES = 8 * 8 * 8 * 8 # board size * board size = number of possible moves\n",
    "PRINT_RESULTS_EVERY_X = 100 # every how many games to print the results\n",
    "WEIGHTS_SAVED=False # if True starts from pre saved weights, if False starts with random weights\n",
    "ILLEGAL_MOVES_ALLOWED = True\n",
    "TRAIN_MODE = 2 # 0 - Learning to make legal moves , 1 - Learning to win the game, 2 - Learning to win the game, reward= evaulation function\n",
    "\n",
    "input_placeholder = tf.compat.v1.placeholder(\"float\", shape=(None, INPUT_NODES))\n",
    "reward_placeholder = tf.compat.v1.placeholder(\"float\", shape=(None,))\n",
    "actual_move_placeholder = tf.compat.v1.placeholder(\"float\", shape=(None, OUTPUT_NODES))\n",
    "\n",
    "if (WEIGHTS_SAVED==False):\n",
    "  hidden_weights_1 = tf.Variable(tf.random.truncated_normal((INPUT_NODES, HIDDEN_NODES[0]), stddev=1. / np.sqrt(INPUT_NODES)))   #random values from a normal distribution\n",
    "  hidden_weights_2 = tf.Variable(\n",
    "      tf.random.truncated_normal((HIDDEN_NODES[0], HIDDEN_NODES[1]), stddev=1. / np.sqrt(HIDDEN_NODES[0])))\n",
    "  hidden_weights_3 = tf.Variable(\n",
    "      tf.random.truncated_normal((HIDDEN_NODES[1], HIDDEN_NODES[2]), stddev=1. / np.sqrt(HIDDEN_NODES[1]))) \n",
    "  output_weights = tf.Variable(tf.random.truncated_normal((HIDDEN_NODES[-1], OUTPUT_NODES), stddev=1. / np.sqrt(OUTPUT_NODES)))\n",
    "\n",
    "  bias_1 = tf.Variable(tf.constant(0.01, shape=(HIDDEN_NODES[0],)))\n",
    "  bias_2 = tf.Variable(tf.constant(0.01, shape=(HIDDEN_NODES[1],)))\n",
    "  bias_3 = tf.Variable(tf.constant(0.01, shape=(HIDDEN_NODES[2],)))\n",
    "  bias_4 = tf.Variable(tf.constant(0.01, shape=(OUTPUT_NODES,)))\n",
    "\n",
    "\n",
    "else:\n",
    "    %store -r saved_weights\n",
    "    hidden_weights_1 = tf.Variable(saved_weights[0])  #saved values\n",
    "    hidden_weights_2 = tf.Variable(saved_weights[1])\n",
    "    hidden_weights_3 = tf.Variable(saved_weights[2])\n",
    "    output_weights = tf.Variable(saved_weights[3])\n",
    "\n",
    "    bias_1 = tf.Variable(saved_weights[4])\n",
    "    bias_2 = tf.Variable(saved_weights[5])\n",
    "    bias_3 = tf.Variable(saved_weights[6])\n",
    "    bias_4 = tf.Variable(saved_weights[7])\n",
    "    \n",
    "    #other neural network for saved player\n",
    "    saved_input_placeholder = tf.compat.v1.placeholder(\"float\", shape=(None, INPUT_NODES))\n",
    "\n",
    "    %store -r saved_weights\n",
    "    saved_hidden_weights_1 = tf.Variable(saved_weights[0])  #saved values\n",
    "    saved_hidden_weights_2 = tf.Variable(saved_weights[1])\n",
    "    saved_hidden_weights_3 = tf.Variable(saved_weights[2])\n",
    "    saved_output_weights = tf.Variable(saved_weights[3])\n",
    "\n",
    "    saved_bias_1 = tf.Variable(saved_weights[4])\n",
    "    saved_bias_2 = tf.Variable(saved_weights[5])\n",
    "    saved_bias_3 = tf.Variable(saved_weights[6])\n",
    "    saved_bias_4 = tf.Variable(saved_weights[7])\n",
    "\n",
    "    saved_hidden_layer_1 = tf.nn.relu(tf.matmul(saved_input_placeholder, saved_hidden_weights_1) + saved_bias_1)\n",
    "    saved_hidden_layer_2 = tf.nn.relu(tf.matmul(saved_hidden_layer_1, saved_hidden_weights_2) + saved_bias_2)\n",
    "    saved_hidden_layer_3 = tf.nn.relu(tf.matmul(saved_hidden_layer_2, saved_hidden_weights_3) + saved_bias_3)\n",
    "    saved_output_layer = tf.nn.softmax(tf.matmul(saved_hidden_layer_3, saved_output_weights) + saved_bias_4)\n",
    "\n",
    "hidden_layer_1 = tf.nn.relu(tf.matmul(input_placeholder, hidden_weights_1) + bias_1)\n",
    "hidden_layer_2 = tf.nn.relu(tf.matmul(hidden_layer_1, hidden_weights_2) + bias_2)\n",
    "hidden_layer_3 = tf.nn.relu(tf.matmul(hidden_layer_2, hidden_weights_3) + bias_3)\n",
    "output_layer = tf.nn.softmax(tf.matmul(hidden_layer_3, output_weights) + bias_4)\n",
    "\n",
    "#other neural network for saved player\n",
    "saved_input_placeholder = tf.compat.v1.placeholder(\"float\", shape=(None, INPUT_NODES))\n",
    "\n",
    "\n",
    "\n",
    "policy_gradient = tf.reduce_sum(input_tensor=tf.reshape(reward_placeholder, (-1, 1)) * actual_move_placeholder * output_layer)\n",
    "train_step = tf.compat.v1.train.AdamOptimizer(LEARN_RATE).minimize(-policy_gradient)\n",
    "\n",
    "sess = tf.compat.v1.Session()\n",
    "sess.run(tf.compat.v1.initialize_all_variables())\n",
    "\n",
    "\n",
    "board_states, actual_moves, rewards = [], [], []\n",
    "episode_number = 1\n",
    "results = collections.deque()\n",
    "\n",
    "\n",
    "def move_transform(move):\n",
    "# transforms a move with n^4 length into a nxnxnxn move\n",
    "    m = list(move).index(1)\n",
    "    x1 = m % 8\n",
    "    m = (m-x1)/8\n",
    "    y1 = m % 8\n",
    "    m = (m-y1)/8\n",
    "    x2 = m % 8\n",
    "    m = (m-x2)/8\n",
    "    y2 = m % 8\n",
    "    return x1,y1,x2,y2 \n",
    "\n",
    "def board_transform(board_state):\n",
    "# transforms board state into input for the neural network\n",
    "    board_state_temp=[]\n",
    "    for i in board_state:\n",
    "        board_state_temp.append(list(i))\n",
    "    pieces1=['p','r','n','b','q','k','P','R','N','B','Q','K']\n",
    "    \n",
    "    \n",
    "    for i in range (8):\n",
    "        for j in range (8):\n",
    "            one_hot=[0]*12\n",
    "            for k in range (12):\n",
    "                if(board_state[i][j]==pieces1[k]):\n",
    "                    one_hot[k]=1\n",
    "                    board_state_temp[i][j]=one_hot\n",
    "                if(board_state[i][j]==0):\n",
    "                    board_state_temp[i][j]=one_hot\n",
    "    for i in range(8):\n",
    "        board_state_temp[i]=np.ravel(board_state_temp[i])\n",
    "    return board_state_temp\n",
    "\n",
    "def make_move(board_state, side):\n",
    "\n",
    "    board_state_temp = board_transform(board_state)\n",
    "    board_state_flat = np.ravel(board_state_temp)\n",
    "    board_states.append(board_state_flat)\n",
    "    probability_of_actions = sess.run(output_layer, feed_dict={input_placeholder: [board_state_flat]})[0]\n",
    "    move_list=0\n",
    "    \n",
    "    # we choose new moves until the move is allowed in the current board state.\n",
    "    while(True):\n",
    "\n",
    "        try:\n",
    "            move = np.random.multinomial(1, probability_of_actions)\n",
    "\n",
    "        except ValueError:\n",
    "            # sometimes because of rounding errors we end up with probability_of_actions summing to greater than 1.\n",
    "            # so need to reduce slightly to be a valid value\n",
    "            \n",
    "            move = np.random.multinomial(1, probability_of_actions / (sum(probability_of_actions) + 1e-7))\n",
    "\n",
    "        if ILLEGAL_MOVES_ALLOWED==True:\n",
    "            break\n",
    "        \n",
    "        if (move_list==0):\n",
    "            move_list=list(available_moves(board_state,side))\n",
    "        \n",
    "        if(move_transform(move) in (move_list)):\n",
    "            break\n",
    "        \n",
    "        # we don't allow to choose the same move again, by changing its probability to 0\n",
    "        probability_of_actions[list(move).index(1)]=0\n",
    "        if sum(probability_of_actions)==0:\n",
    "          break\n",
    "        probability_of_actions=probability_of_actions*(1/sum(probability_of_actions))\n",
    "        \n",
    "    actual_moves.append(move)\n",
    "\n",
    "\n",
    "    return move_transform(move)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def policy_gradient_player(board_state, side):\n",
    "# Chooses the move with the highest probability instead of randomly choosing\n",
    "    \n",
    "    board_state_temp = board_transform(board_state)\n",
    "    board_state_flat = np.ravel(board_state_temp)\n",
    "    board_states.append(board_state_flat)\n",
    "    probability_of_actions = sess.run(output_layer, feed_dict={input_placeholder: [board_state_flat]})[0]\n",
    "\n",
    "    move=[0]*8*8*8*8\n",
    "    move[list(probability_of_actions).index(max(list(probability_of_actions)))] = 1\n",
    "\n",
    "    \n",
    "    # we choose new moves until the move is allowed in the current board state.\n",
    "    while(move_transform(move) not in (list(available_moves(board_state,side)))):\n",
    "        \n",
    "        if ILLEGAL_MOVES_ALLOWED==True:\n",
    "            break\n",
    "        \n",
    "        # we don't allow to choose the same move again, by changing its probability to 0\n",
    "        probability_of_actions[list(move).index(1)]=0\n",
    "        if sum(probability_of_actions)==0:\n",
    "          break       \n",
    "        probability_of_actions=probability_of_actions*(1/sum(probability_of_actions))\n",
    "\n",
    "        move=[0]*8*8*8*8\n",
    "        move[list(probability_of_actions).index(max(list(probability_of_actions)))] = 1\n",
    "\n",
    "\n",
    "\n",
    "    actual_moves.append(move)\n",
    "\n",
    "\n",
    "    return move_transform(move)\n",
    "\n",
    "def saved_player(board_state, side):\n",
    "# Chooses the move with the highest probability instead of randomly choosing\n",
    "    \n",
    "    board_state_temp = board_transform(board_state)\n",
    "    board_state_flat = np.ravel(board_state_temp)\n",
    "    board_states.append(board_state_flat)\n",
    "    probability_of_actions = sess.run(output_layer, feed_dict={input_placeholder: [board_state_flat]})[0]\n",
    "\n",
    "    # we choose new moves until the move is allowed in the current board state.\n",
    "    while(True):\n",
    "\n",
    "        try:\n",
    "            move = np.random.multinomial(1, probability_of_actions)\n",
    "\n",
    "        except ValueError:\n",
    "            # sometimes because of rounding errors we end up with probability_of_actions summing to greater than 1.\n",
    "            # so need to reduce slightly to be a valid value\n",
    "            \n",
    "            move = np.random.multinomial(1, probability_of_actions / (sum(probability_of_actions) + 1e-7))\n",
    "\n",
    "        \n",
    "        if ILLEGAL_MOVES_ALLOWED==True:\n",
    "            break\n",
    "            \n",
    "        \n",
    "        if(move_transform(move) in (list(available_moves(board_state,side)))):\n",
    "          break\n",
    "        \n",
    "        # we don't allow to choose the same move again, by changing its probability to 0\n",
    "        probability_of_actions[list(move).index(1)]=0\n",
    "        if sum(probability_of_actions)==0:\n",
    "          break\n",
    "        probability_of_actions=probability_of_actions*(1/sum(probability_of_actions))\n",
    "    \n",
    "    actual_moves.append(move)\n",
    "\n",
    "\n",
    "    return move_transform(move)\n",
    "\n",
    "\n",
    "turns=[]\n",
    "win_rates=[]\n",
    "game_lengths=[]\n",
    "seconds = time.time()\n",
    "\n",
    "\n",
    "while True:\n",
    "\n",
    "    reward = play_game(make_move, random_player, log = 0)\n",
    "    turn = reward[2]\n",
    "    points = reward[1]\n",
    "    reward = reward[0]\n",
    "    results.append(reward)\n",
    "    if len(results) > PRINT_RESULTS_EVERY_X:\n",
    "        results.popleft()\n",
    "\n",
    "    last_game_length = len(board_states) - len(rewards)\n",
    "\n",
    "\n",
    "    #Learning to make legal moves\n",
    "    #Reward = game length\n",
    "    if TRAIN_MODE == 0:\n",
    "        #the reward is the length of the game - the number of legal\n",
    "        #rewards += ([last_game_length-1] * (last_game_length-1))\n",
    "        rewards += ([1] * (last_game_length-1))\n",
    "        rewards += ([-1])\n",
    "        turns+=([(turn-1)/2])\n",
    "        \n",
    "    \n",
    "    #Learning to win the game\n",
    "    #Reward = 1 if won -1 if lost\n",
    "    if TRAIN_MODE == 1:\n",
    "        # we scale here so winning quickly is better winning slowly and loosing slowly better than loosing quick\n",
    "        if(float(last_game_length) != 0) :\n",
    "            reward /= float(last_game_length)\n",
    "        rewards += ([reward] * last_game_length)\n",
    "        \n",
    "    \n",
    "    #Reward = position evaluation\n",
    "    if TRAIN_MODE == 2:\n",
    "        print(points)\n",
    "        rewards += (points)\n",
    "    \n",
    "    episode_number += 1\n",
    "    \n",
    "    if episode_number % BATCH_SIZE == 0:\n",
    "        normalized_rewards = rewards - np.mean(rewards)\n",
    "\n",
    "        if TRAIN_MODE==0:\n",
    "            print(rewards)\n",
    "                \n",
    "        if np.std(normalized_rewards)!=0:\n",
    "            normalized_rewards /= np.std(normalized_rewards)\n",
    "\n",
    "        \n",
    "            sess.run(train_step, feed_dict={input_placeholder: board_states,\n",
    "                                        reward_placeholder: normalized_rewards,\n",
    "                                        actual_move_placeholder: actual_moves})\n",
    "\n",
    "            # clear batches\n",
    "            del board_states[:]\n",
    "            del actual_moves[:]\n",
    "            del rewards[:]\n",
    "\n",
    "    if episode_number % PRINT_RESULTS_EVERY_X == 0:\n",
    "        print(\"episode: %s win_rate: %s                                     Time elapsed : %s\" % (episode_number,results.count(1) / (PRINT_RESULTS_EVERY_X), round(time.time()-seconds,3) ))\n",
    "        seconds = time.time()\n",
    "        win_rates.append(results.count(1) / (PRINT_RESULTS_EVERY_X))\n",
    "        if TRAIN_MODE == 0:\n",
    "            print(\"avg game length: %s\" % (sum(turns)/len(turns)))\n",
    "            game_lengths.append(sum(turns)/len(turns))\n",
    "            turns=[]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the weights and biases\n",
    "\n",
    "saved_weights=[]\n",
    "\n",
    "def save_weights(hidden_weights_1,hidden_weights_2,hidden_weights_3,output_weights,bias_1,bias_2,bias_3,bias_4):\n",
    "  weights = []\n",
    "  weights.append(sess.run(hidden_weights_1))\n",
    "  weights.append(sess.run(hidden_weights_2))\n",
    "  weights.append(sess.run(hidden_weights_3))\n",
    "  weights.append(sess.run(output_weights))\n",
    "  weights.append(sess.run(bias_1))\n",
    "  weights.append(sess.run(bias_2))\n",
    "  weights.append(sess.run(bias_3))\n",
    "  weights.append(sess.run(bias_4))\n",
    "  return weights\n",
    "\n",
    "saved_weights=save_weights(hidden_weights_1,hidden_weights_2,hidden_weights_3,output_weights,bias_1,bias_2,bias_3,bias_4)\n",
    "\n",
    "%store saved_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random_player_win_rates = [0.5860]*len(win_rates)\n",
    "random_player_illegal_win_rates = [0.08479]*len(win_rates)\n",
    "\n",
    "f = plt.figure() \n",
    "f.set_figwidth(8) \n",
    "f.set_figheight(5) \n",
    "\n",
    "plt.plot(game_lengths,  label=\"Policy gradient játékos\")\n",
    "#plt.plot(random_player_win_rates, 'g', label=\"Random játékos\")\n",
    "#plt.plot(random_player_illegal_win_rates,'r', label=\"Illegális random játékos\")\n",
    "plt.ylabel('szabályos lépések száma játékonként')\n",
    "plt.xlabel('játékok száma (száz játék)')\n",
    "#legend=plt.legend(loc='center right')\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "max_depth=4\n",
    "\n",
    "def evaluate(board_state):\n",
    "    \"\"\"Get a rough score for how good we think this board position is for the plus_player. Does this based on number of\n",
    "    2 in row lines we have.\n",
    "    Args:\n",
    "        board_state (3x3 tuple of int): The board state we are evaluating\n",
    "    Returns:\n",
    "        int: evaluated score for the position for the plus player, posative is good for the plus player, negative good\n",
    "            for the minus player\n",
    "    \"\"\"\n",
    "    pieces=['p','r','n','b','q','k','P','R','N','B','Q','K']\n",
    "    points=[1,5,3,3,9,100,-1,-5,-3,-3,-9,-100]\n",
    "    point=0\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            for k in range(12):\n",
    "                if(board_state[i][j]==pieces[k]):\n",
    "                    point=point+points[k]\n",
    "    return point\n",
    "\n",
    "\n",
    "\n",
    "def min_max(board_state, side, max_depth, evaluation_func=evaluate):\n",
    "    \"\"\"Runs the min_max_algorithm on a given board_sate for a given side, to a given depth in order to find the best\n",
    "    move\n",
    "    Args:\n",
    "        board_state (3x3 tuple of int): The board state we are evaluating\n",
    "        side (int): either +1 or -1\n",
    "        max_depth (int): how deep we want our tree to go before we use the evaluate method to determine how good the\n",
    "        position is.\n",
    "        evaluation_func (board_state -> int): Function used to evaluate the position for the plus player\n",
    "    Returns:\n",
    "        (best_score(int), best_score_move((int, int)): the move found to be best and what it's min-max score was\n",
    "    \"\"\"\n",
    "    best_score = None\n",
    "    best_score_move = None\n",
    "\n",
    "    moves = list(available_moves(board_state,side))\n",
    "    if not moves:\n",
    "        # this is a draw\n",
    "        return 0, None\n",
    "\n",
    "    for move in moves:\n",
    "        new_board_state = apply_move(board_state, move)\n",
    "        winner = has_winner(new_board_state)\n",
    "        if winner != 0:\n",
    "            return winner * 10000, move\n",
    "        else:\n",
    "            if max_depth <= 1:\n",
    "                score = evaluation_func(new_board_state)\n",
    "            else:\n",
    "                score, _ = min_max(new_board_state, -side, max_depth - 1)\n",
    "            if side > 0:\n",
    "                if best_score is None or score > best_score:\n",
    "                    best_score = score\n",
    "                    best_score_move = move\n",
    "            else:\n",
    "                if best_score is None or score < best_score:\n",
    "                    best_score = score\n",
    "                    best_score_move = move\n",
    "    return best_score, best_score_move\n",
    "\n",
    "\n",
    "def min_max_alpha_beta(board_state, side, max_depth, evaluation_func=evaluate, alpha=-sys.float_info.max,\n",
    "                       beta=sys.float_info.max):\n",
    "    \"\"\"Runs the min_max_algorithm on a given board_sate for a given side, to a given depth in order to find the best\n",
    "    move\n",
    "    Args:\n",
    "        board_state (3x3 tuple of int): The board state we are evaluating\n",
    "        side (int): either +1 or -1\n",
    "        max_depth (int): how deep we want our tree to go before we use the evaluate method to determine how good the\n",
    "        position is.\n",
    "        evaluation_func (board_state -> int): Function used to evaluate the position for the plus player\n",
    "        alpha (float): Used when this is called recursively, normally ignore\n",
    "        beta (float): Used when this is called recursively, normally ignore\n",
    "    Returns:\n",
    "        (best_score(int), best_score_move((int, int)): the move found to be best and what it's min-max score was\n",
    "    \"\"\"\n",
    "    best_score_move = None\n",
    "    moves = list(available_moves(board_state,side))\n",
    "    if not moves:\n",
    "        return 0, None\n",
    "\n",
    "    for move in moves:\n",
    "        new_board_state = apply_move(board_state, move)\n",
    "        winner = has_winner(new_board_state)\n",
    "        if winner != 0:\n",
    "            return winner * 10000, move\n",
    "        else:\n",
    "            if max_depth <= 1:\n",
    "                score = evaluate(new_board_state)\n",
    "            else:\n",
    "                score, _ = min_max_alpha_beta(new_board_state, -side, max_depth - 1, evaluation_func, alpha, beta)\n",
    "\n",
    "        if side > 0:\n",
    "            if score > alpha:\n",
    "                alpha = score\n",
    "                best_score_move = move\n",
    "        else:\n",
    "            if score < beta:\n",
    "                beta = score\n",
    "                best_score_move = move\n",
    "        if alpha >= beta:\n",
    "            break\n",
    "\n",
    "    return alpha if side > 0 else beta, best_score_move\n",
    "\n",
    "\n",
    "def min_max_player(board_state, side):\n",
    "    print (evaluate(board_state))\n",
    "    return min_max_alpha_beta(board_state, side, max_depth)[1]  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
